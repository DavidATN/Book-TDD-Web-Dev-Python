[[chapter_10_ansible]]
== Infrastructure As Code with Ansbile

.ðŸš§ Warning, this chapter is heavily under construction
*******************************************************************************
As part of my work on the third edition of the book,
I'm rewriting the deployment chapters,
but I haven't really started on this chapter yet.
Sorry!

Following along with this chapter is going to be pretty
much impossible while I'm still half-done.

It might be best to skip ahead to [[chapter_organising_test_files]]

*******************************************************************************

// TODO move this to next chapter

NOTE: Why not ping me a note once your site is live on the web,
    and send me the URL?
    It always gives me a warm and fuzzy feeling...
    obeythetestinggoat@gmail.com.




[quote, 'Cay Horstman']
______________________________________________________________
Automate, automate, automate.
______________________________________________________________

((("deployment", "automating with Fabric", id="Dfarbric11")))
((("infrastructure as code")))
Automating deployment is critical for our staging tests to mean anything.
By making sure the deployment procedure is repeatable, we give ourselves
assurances that everything will go well when we deploy to production. (These
days people sometimes use the words "infrastructure as code" to describe
automation of deployments, and provisioning.)


Getting a Domain Name
~~~~~~~~~~~~~~~~~~~~~

((("staging sites", "domain names")))((("domain names")))We're
going to need a couple of domain names at this point in the book--they
can both be subdomains of a single domain.  I'm going to use
'superlists.ottg.eu' and 'superlists-staging.ottg.eu'.
If you don't already own a domain, this is the time to register one! Again,
this is something I really want you to 'actually' do.  If you've never
registered a domain before, just pick any old registrar and buy a cheap one--it
should only cost you $5 or so, and you can even find free ones.
I promise seeing your site on a "real" website will be a thrill.



Manually Provisioning a Server to Host Our Site
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

((("staging sites", "manual server provisioning", id="SSserver09")))((("server provisioning", id="seerver09")))We
can separate out "deployment" into two tasks:

- 'Provisioning' a new server to be able to host the code
- 'Deploying' a new version of the code to an existing server

Some people like to use a brand new server for every deployment--it's what we
do at PythonAnywhere.  That's only necessary for larger, more complex sites
though, or major changes to an existing site. For a simple site like ours, it
makes sense to separate the two tasks.  And, although we eventually want both
to be completely automated, we can probably live with a manual provisioning
system for now.

As you go through this chapter, you should be aware that provisioning is
something that varies a lot, and that as a result there are few universal
best practices for deployment.  So, rather than trying to remember the
specifics of what I'm doing here, you should be trying to understand the
rationale, so that you can apply the same kind of thinking in the
specific future circumstances you encounter.


Choosing Where to Host Our Site
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


((("hosting services")))There
are loads of different solutions out there these days, but they broadly
fall into two camps:

- Running your own (possibly virtual) server
- Using a ((("Platform-As-A-Service (PaaS)")))Platform-As-A-Service (PaaS)
  offering like Heroku, OpenShift, or [keep-together]#PythonAnywhere#



((("PythonAnywhere")))Particularly
for small sites, a PaaS offers a lot of advantages, and I would
definitely recommend looking into them.  We're not going to use a PaaS in this
book however, for several reasons.  Firstly, I have a conflict of interest, in
that I think PythonAnywhere is the best, but then again I would say that
because I work there.  Secondly, all the PaaS offerings are quite different,
and the procedures to deploy to each vary a lot--learning about one doesn't
necessarily tell you about the others. Any one of them might radically change their process or business model by the time you get to read this book.

Instead, we'll learn just a tiny bit of good old-fashioned server admin,
including SSH and web server config.  They're unlikely to ever go away, and
knowing a bit about them will get you some respect from all the grizzled
dinosaurs out there.

What I have done is to try to set up a server in such a way that's a bit
like the environment you get from a PaaS, so you should be able to apply the
lessons we learn in the deployment section, no matter what provisioning
solution you choose.



Spinning Up a Server
^^^^^^^^^^^^^^^^^^^^

I'm not going to dictate how you do this--whether you choose Amazon AWS,
Rackspace, Digital Ocean, your own server in your own data centre or a
Raspberry Pi in a cupboard under the stairs, any solution should be fine, as
long as:

* Your server is running Ubuntu 18.04 (aka "Bionic/LTS").

* You have root access to it.

* It's on the public internet.

* You can SSH into it.

I'm recommending Ubuntu as a distro because it's easy to get Python 3.6 on it
and it has some specific ways of configuring Nginx, which I'm going to make use
of next.  If you know what you're doing, you can probably get away with using
something else, but you're on your own.

((("Linux servers")))If
you've never started a Linux server before and you have absolutely no idea
where to start, I wrote a
https://github.com/hjwp/Book-TDD-Web-Dev-Python/blob/master/server-quickstart.md[very brief guide on GitHub].


NOTE: ((("getting help")))Some
    people get to this chapter, and are tempted to skip the domain bit,
    and the "getting a real server" bit, and just use a VM on their own PC.
    Don't do this. It's 'not' the same, and you'll have more difficulty
    following the instructions, which are complicated enough as it is.  If
    you're worried about cost, have a look at the link above for free options.


User Accounts, SSH, and Privileges
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In these instructions, I'm assuming that you have a nonroot user account set
up that has "sudo" privileges, so whenever we need to do something that
requires root access, we use sudo, and I'm explicit about that in the various
instructions that follow.

My user is called "elspeth", but you can call yours whatever you like!  Just
remember to substitute it in all the places I've hardcoded it below.
See the guide linked above if you need tips on creating a sudo user.




.General Server Debugging Tips
*******************************************************************************

The most important lesson to remember from this chapter is to work
incrementally, make one change at a time, and run your tests frequently.

When things (inevitably) go wrong, resist the temptation to flail about and
make other unrelated changes in the hope that things will start working again;
instead, stop, go backward if necessary to get to a working state, and figure
out what went wrong before moving forward again.

It's just as easy to fall into the Refactoring-Cat trap on the server!

*******************************************************************************






Configuring Domains for Staging and Live
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

We don't want to be messing about with IP addresses all the time, so we should
point our staging and live domains to the server. At my registrar, the control
screens looked a bit like <<registrar-control-screens>>.

[[registrar-control-screens]]
.Domain setup
image::images/twp2_0902.png["Registrar control screens for two domains"]

//TODO: adjust illustration to show "superlists" not "book-example"

((("A-Records")))In
the DNS system, pointing a domain at a specific IP address is called an
"A-Record".  All registrars are slightly different, but a bit of clicking
around should get you to the right screen in yours.  You'll need two A-records:
one for the staging address and one for the live one.  No need to worry about
any other type of record.

DNS records take some time to "propagate" around the world (it's controlled
by a setting called "TTL", Time To Live), so once you've set up your A-record,
you can check its progress on a "propagation checking" service like this one: https://www.whatsmydns.net/#A/superlists-staging.ottg.eu[].



=== Old content from Provisioning with Ansible chapter


((("Ansible", id="ansible29")))((("continuous deployment tools")))((("deployment", "continuous deployment tools")))We
used Fabric to automate deploying new versions of the source code to our
servers.  But provisioning a fresh server, and updating the Nginx and Gunicorn
config files, was all left as a manual process.

This is the kind of job that's increasingly given to tools called
"Configuration Management" or "Continuous Deployment" tools.  Chef and Puppet
were the first popular ones, and in the Python world there's Salt and Ansible.

Of all of these, Ansible is the easiest to get started with.  We
can get it working with just two files:

    pip2 install --user ansible  # Python 2 sadly


An "inventory file" at _deploy_tools/inventory.ansible_ defines what servers we
can run against:

[role="sourcecode"]
.deploy_tools/inventory.ansible
====
[source,ini]
----
[live]
superlists.ottg.eu ansible_become=yes ansible_ssh_user=elspeth

[staging]
superlists-staging.ottg.eu ansible_become=yes ansible_ssh_user=elspeth

[local]
localhost ansible_ssh_user=root ansible_ssh_port=6666 ansible_host=127.0.0.1
----
====

(The local entry is just an example, in my case a Virtualbox VM, with port
forwarding for ports 22 and 80 set up.)


Installing System Packages and Nginx
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Next the Ansible "playbook", which defines what to do on the server.  This
uses a syntax called YAML:

[role="sourcecode"]
.deploy_tools/provision.ansible.yaml
====
[source,yaml]
----
---

- hosts: all

  vars:
      host: "{{ inventory_hostname }}"

  tasks:

    - name: Deadsnakes PPA to get Python 3.6
      apt_repository:
        repo='ppa:deadsnakes/ppa'
    - name: make sure required packages are installed
      apt: pkg=nginx,git,python3.7,python3.7-venv state=present

    - name: allow long hostnames in nginx
      lineinfile:
        dest=/etc/nginx/nginx.conf
        regexp='(\s+)#? ?server_names_hash_bucket_size'
        backrefs=yes
        line='\1server_names_hash_bucket_size 64;'

    - name: add nginx config to sites-available
      template: src=./nginx.conf.j2 dest=/etc/nginx/sites-available/{{ host }}
      notify:
          - restart nginx

    - name: add symlink in nginx sites-enabled
      file:
          src=/etc/nginx/sites-available/{{ host }}
          dest=/etc/nginx/sites-enabled/{{ host }}
          state=link
      notify:
          - restart nginx
----
====


The `inventory_hostname` variable is the domain name of the server we're running against.
I'm using the `vars` section to rename it to "host", just for convenience.


In this section, we install our required software using `apt`, tweak the Nginx
config to allow long hostnames using a regular expression replacer, and then write the Nginx config file using a template.  This is a modified version
of the template file we saved into 'deploy_tools/nginx.template.conf' in
<<chapter_09_docker>>, but it now uses a specific templating syntax--Jinja2, which is
actually a lot like the Django template syntax:

[role="sourcecode"]
.deploy_tools/nginx.conf.j2
====
----
server {
    listen 80;
    server_name {{ host }};

    location /static {
        alias /home/{{ ansible_ssh_user }}/sites/{{ host }}/static;
    }

    location / {
        proxy_set_header Host {{ host }};
        proxy_pass http://unix:/tmp/{{ host }}.socket;
    }
}
----
====


Configuring Gunicorn, and Using Handlers to Restart Services
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Here's the second half of our playbook:

[role="sourcecode"]
.deploy_tools/provision.ansible.yaml
====
[source,yaml]
----
    - name: write gunicorn service script
      template:
          src=./gunicorn.service.j2
          dest=/etc/systemd/system/gunicorn-{{ host }}.service
      notify:
          - restart gunicorn

  handlers:
    - name: restart nginx
      service:  name=nginx state=restarted

    - name: restart gunicorn
      systemd:
          name=gunicorn-{{ host }}
          daemon_reload=yes
          enabled=yes
          state=restarted

----
====


Once again we use a template for our Gunicorn config:

[role="sourcecode"]
.deploy_tools/gunicorn.service.j2
====
[source,bash]
----
[Unit]
Description=Gunicorn server for {{ host }}

[Service]
User={{ ansible_ssh_user }}
WorkingDirectory=/home/{{ ansible_ssh_user }}/sites/{{ host }}
EnvironmentFile=/home/{{ ansible_ssh_user }}/sites/{{ host }}/.env
Restart=on-failure
ExecStart=/home/{{ ansible_ssh_user }}/sites/{{ host }}/.venv/bin/gunicorn \
    --bind unix:/tmp/{{ host }}.socket \
    --access-logfile ../access.log \
    --error-logfile ../error.log \
    superlists.wsgi:application

[Install]
WantedBy=multi-user.target
----
====

Then we have two "handlers" to restart Nginx and Gunicorn.  Ansible is
clever, so if it sees multiple steps all call the same handlers, it
waits until the last one before calling it.


And that's it!  The command to kick all these off is:

[role="small-code"]
----
ansible-playbook -i inventory.ansible provision.ansible.yaml --limit=staging --ask-become-pass
----

Lots more info in the https://docs.ansible.com/[Ansible docs].


What to Do Next
~~~~~~~~~~~~~~~

I've just given a little taster of what's possible with Ansible.  But the more
you automate about your deployments, the more confidence you will have in
them.  Here are a few more things to look into.

Move Deployment out of Fabric and into Ansible
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


((("Fabric", "moving deployment to Ansible")))We've
seen that Ansible can help with some aspects of provisioning, but it can
also do pretty much all of our deployment for us.  See if you can extend the
playbook to do everything that we currently do in our Fabric deploy script,
including notifying the restarts as required.



Use Vagrant to Spin Up a Local VM
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



Running tests against the staging site gives us the ultimate confidence that
things are going to work when we go live, but we can also use a VM on our
local machine.

Download Vagrant and Virtualbox, and see if you can get Vagrant to build a
dev server on your own PC, using our Ansible playbook to deploy code to it.
Rewire the FT runner to be able to test against the local VM.

Having a Vagrant config file is particularly helpful when working
in a team--it helps new developers to spin up servers that look exactly
like yours.((("", startref="ansible29")))




Deploying to Live
^^^^^^^^^^^^^^^^^


So, let's try using it for our live site!

[role="small-code against-server"]
[subs=""]
----
$ <strong>fab deploy:host=elspeth@superlists.ottg.eu</strong>

Done.
Disconnecting from elspeth@superlists.ottg.eu... done.
----


'Brrp brrp brpp'. You can see the script follows a slightly different path,
doing a `git clone` to bring down a brand new repo instead of a `git pull`.
It also needs to set up a new virtualenv from scratch, including a fresh
install of pip and Django. The `collectstatic` actually creates new files this
time, and the `migrate` seems to have worked too.



Git Tag the Release
~~~~~~~~~~~~~~~~~~~


((("Git", "tagging releases")))One
final bit of admin.  In order to preserve a historical marker,
we'll use Git tags to mark the state of the codebase that reflects
what's currently live on the server:

[role="skipme"]
[subs="specialcharacters,quotes"]
----
$ *git tag LIVE*
$ *export TAG=$(date +DEPLOYED-%F/%H%M)*  # this generates a timestamp
$ *echo $TAG* # should show "DEPLOYED-" and then the timestamp
$ *git tag $TAG*
$ *git push origin LIVE $TAG* # pushes the tags up
----

Now it's easy, at any time, to check what the difference is between
our current codebase and what's live on the servers.  This will come
in useful in a few chapters, when we look at database migrations. Have
a look at the tag in the history:

[subs="specialcharacters,quotes"]
----
$ *git log --graph --oneline --decorate*
[...]
----


Anyway, you now have a live website!  Tell all your friends!  Tell your mum, if
no one else is interested!  And, in the next chapter, it's back to coding
again.((("", startref="Fstage11")))



Further Reading
~~~~~~~~~~~~~~~


((("Fabric", "additional resources")))((("automated deployment", "additional resources")))There's
no such thing as the One True Way in deployment, and I'm no grizzled
expert in any case.  I've tried to set you off on a reasonably sane path, but
there's plenty of things you could do differently, and lots, lots more to learn
besides.  Here are some resources I used for inspiration:


* http://hynek.me/talks/python-deployments[Solid Python Deployments for Everybody] by Hynek Schlawack

* http://bit.ly/U6tUo5[Git-based fabric deployments are awesome] by Dan Bravender

* The deployment chapter of <<twoscoops,Two Scoops of Django>> by Dan
  Greenfeld and Audrey Roy

* http://12factor.net/[The 12-factor App] by the Heroku team



[role="pagebreak-before less_space"]
.Automated Deployments
*******************************************************************************

Fabric::
    ((("automated deployment", "best practices for")))((("Fabric", "automated deployment best practices")))Fabric
lets you run commands on servers from inside Python scripts. This
    is a great tool for automating server admin tasks.


Idempotency::
    ((("idempotency")))If
your deployment script is deploying to existing servers, you need to
    design them so that they work against a fresh installation 'and' against
    a server that's already configured.


Keep config files under source control::
    Make sure your only copy of a config file isn't on the server!  They
    are critical to your application, and should be under version control
    like anything else.

Automating provisioning::
    Ultimately, 'everything' should be automated, and that includes spinning up
    brand new servers and ensuring they have all the right software installed.
    This will involve interacting with the API of your hosting provider.

Configuration management tools::
    ((("configuration management tools")))((("Ansible")))((("Vagrant")))Fabric
is very flexible, but its logic is still based on scripting. More
    advanced tools take a more "declarative" approach, and can make your life
    even easier.  Ansible and Vagrant are two worth checking out (see
    <<appendix3>>), but there are many more (Chef, Puppet, Salt, Juju...).((("", startref="Dfarbric11")))

*******************************************************************************

