[[chapter_09_docker]]
== Deployment Part 1: Containerization aka Docker

[quote, 'http://bit.ly/2uhCXnH[Devops Borat]']
______________________________________________________________
Is all fun and game until you are need of put it in production.
______________________________________________________________

It's time to deploy the first version of our site and make it public.
They say that if you wait until you feel _ready_ to ship,
then you've waited too long.

Is our site usable? Is it better than nothing? Can we make lists on it?
Yes, yes, yes.

No, you can't log in yet.
No, you can't mark tasks as completed.
But do we really need any of that stuff?
Not really--and you can never be sure
what your users are _actually_ going to do with your site
once they get their hands on it.
We think our users want to use the site for to-do lists,
but maybe they actually want to use it
to make "top 10 best fly-fishing spots" lists,
for which you don't _need_ any kind of "mark completed" function.
We won't know until we put it out there.

Over the next couple of chapters we're going to go through
and actually deploy our site to a real, live web server.

You might be tempted to skip this bit--there's
lots of daunting stuff in it,
and maybe you think this isn't what you signed up for.
But I _strongly_ urge you to give it a go.
This is one of the sections of the book I'm most pleased with,
and it's one that people often write to me
saying they were really glad they stuck through it.

If you've never done a server deployment before,
it will demystify a whole world for you,
and there's nothing like the feeling of seeing your site live
on the actual internet.
Give it a buzzword name like "DevOps"
if that's what it takes to convince you it's worth it.

.ðŸš§ Warning, this chapter is under construction
*******************************************************************************
As part of my work on the third edition of the book,
I'm rewriting the deployment chapters,
and this chapter is still a very rough draft I'm afraid.
Sorry!

Following along with this chapter is going to be pretty tricky
in its current state, although you might be able to skim
through the content out of curiosity.

It might be best to skip ahead to <<chapter_12_organising_test_files>>

*******************************************************************************

=== TDD and the Danger Areas of Deployment

Deploying a site to a live web server can be a tricky topic.
Oft-heard is the forlorn cry __"but it works on my machine!"__

((("deployment", "danger areas of")))
Some of the danger areas of deployment include:

Networking::
    Once we're off our own machine, networking issues come in:
    making sure that DNS is routing our domain
    to the correct IP address for our server,
    making sure our server is configured
    to listen to traffic coming in from the world,
    making sure it's using the right ports,
    and making sure any firewalls in the way
    are configured to let traffic through.

Dependencies::
    We need to make sure that the packages our software relies on
    (Python, Django, and so on) are installed on the server,
    and have the correct versions.

The database::
    There can be permissions and path issues,
    and we need to be careful about preserving data between deploys.

Static files (CSS, JavaScript, images, etc.)::
    Web servers usually need special configuration for serving these.
    ((("static files", "challenges of")))

Security and Configuration::
    Once we're on the public internet,
    we need to worry more about security.
    Various settings that are really useful for local development
    (like the Django debug page)
    become dangerous in production
    (because they expose our source code in tracebacks).


One way to approach the problem is to get a server,
and start manually configuring and installing everything,
hacking about until it works,
and maybe think about automating things laterfootnote:[
This was, more or less, the approach I took in earlier editions of the book.
With a fair bit of testing thrown in of course.].

But if there's one thing we've learned
in the world of agile/lean software development,
it's that taking smaller steps usually pays off.

How can we take smaller, safer steps towards a production deployment?
Can we _simulate_ the process of moving to a server,
so that we can iron out all the bugs,
before we actually take the plunge?
Can we then make small changes one at a time,
solving problems one by one,
rather than having to bite off everything in one mouthful?

Absolutely we can.  And from the title of the chapter,
I'm sure you're already guessing that Docker is going
to be part of the answer.


=== Docker, Containers and Virtualization

// TODO: experiment with moving this intro to docker
// to before the tdd danger areas bit.

// mention that ppl can skip this section if they already know obvs.

Docker is a commercial product that wraps several free
and open source technologies from the world of Linux,
sometimes referred to as "containerization".

You may have already heard of the idea of "virtualization",
which allows a single physical computer to pretend to be several machines.
Pioneered by IBM (amongst others) on mainframes in the 1960s,
it rose to mainstream adoption in the 90s,
where it was sold as a way to optimise resource usage in datacentres.
AWS, for example, was an offshoot of Amazon,
who were using virtualization already,
and realised they could sell some spare capacity on their servers
to customers outside the business.

So when you come to deploy your code to a real server in a datacentre,
it will be using virtualization.
And actually you can use virtualization on your own machine,
with software like Virtualbox or KVM.

But that can be fiddly to set up!
And nowadays, thanks to containerization, we can do better.
Because containerization is a kind of even-more-virtual virtualization.

Conceptually, "regular" virtualization works at the hardware level,
it gives you multiple virtual machines (VMs)
that pretend to be physical computers, on a single real machine.
So you can run multiple operating systems inside separate VMs
on the same physical box.

Containers work at the operating system level.
It gives you multiple virtual operating systems that
all run on a single real OS.
So you can run multiple programs inside separate virtual operating systems,
using a single real host operating system and kernel.

The upshot of this is that containers are much "cheaper".
You can start one up in milliseconds,
and you can run hundreds on the same machine.


==== Containers and your CV

That's all well and good for the _theoretical_ justification.
But let's get to the _real_ reason for using this technology,
which, as always, is:
"it's fashionable so it's going to look good on my CV."

For the purposes of this book,
that's not such a bad justification really.
Yes I think it's going to be a nice way to have a "pretend"
deployment on our own machine, before we try the real one.

But also, containers are so popular nowadays,
that it's very likely that you're going to encounter them at work
(if you haven't already).
For many working developers,
a container image is the final artifact of their work,
it's what they "deliver",
and most of the rest of the deployment process
is taken care of by someone else.


=== Docker and the danger areas of deployment

(TODO: expand this section, is just bullet points atm)

How will containerizing our software help with the danger areas?

* Containers are like a little virtual server,
  so they will force us to address many of the problems
  like dependency management and configuration.

* We can use the containers to package up as much
  of the functionality of our application as possible,
  which in turn will minimise the amount of configuration
  we need to do to our actual servers

* We can test our containers work by running our functional tests
  against them.

* Later, when we deploy our containers to a staging site,
  we can run the FTs against that too.

* If we automate container creation and deployment to staging,
  and we've tested both those things, then we will have
  minimised the risk of deployment to production.

////
old content follows. is there anything we want to rescue from here?

But there are solutions to all of these.  In order:

((("staging sites", "benefits of")))
*   Using a 'staging site', on the same infrastructure as the production site,
    can help us test out our deployments and get things right before we go to
    the "real" site.


*   We can also 'run our functional tests against the staging site'. That will
    reassure us that we have the right code and packages on the server, and
    since we now have a "smoke test" for our site layout, we'll know that the
    CSS is loaded correctly.


*   ((("virtual environment (virtualenv)", "server-based")))Just
    like on our own PC, a 'virtualenv' is useful on the server for
    managing packages and dependencies when you might be running more than one
    Python [keep-together]#application#.

*   ((("automated deployment", "benefits of")))((("automated deployment", see="also Fabric")))And
    finally, 'automation, automation, automation'.  By using an automated
    script to deploy new versions, and by using the same script to deploy to
    staging and production, we can reassure ourselves that staging is as much
    like live as possible.footnote:[What I'm calling a "staging" server, some people would
    call a "development" server, and some others would also like to distinguish
    "preproduction" servers.  Whatever we call it, the point is to have
    somewhere we can try our code out in an environment that's as similar as
    possible to the real production server.]

////


////
I'm planning to host my staging server at 'superlists-staging.ottg.eu':


NOTE: A clarification: in this chapter, we run tests 'against' our staging
    server, not 'on' our staging server.  So we still run the tests from our
    own laptop, but they target the site that's running on the server.
////


=== Our deployment procedure

Over the next few pages I'm going to go through _a_ deployment procedure.
It isn't meant to be the _perfect_ deployment procedure,
so please don't take it as being best practice,
or a recommendation--it's meant to be an illustration,
to show the kinds of issues involved in deployment,
and where testing fits in.


**This chapter: containerizing our software**

* Adapt our FTs so they can run against a container

* Build a minimal Dockerfile with everything we need to run our site,
  learn how to build and run a container on our machine,
  and run our FTs against it.

* Gradually, incrementally change the container configuration
  to make it production-ready,
  regularly runing the Fts to check we didn't break anything.

// gunicorn, DEBUG=False, secret key, etc


**Next chapter: automated deployment**

* (maybe?) ssh into the server and configure it manually first?
* figure out all the SSH permissions and DNS issues
* we'll use Ansible to build an automated script that can deploy
  our container to stagingfootnote:[
What I'm calling a "staging" server, some people would
call a "development" server, and some others would also like to distinguish
"preproduction" servers.  Whatever we call it, the point is to have
somewhere we can try our code out in an environment that's as similar as
possible to the real production server.]
* use our FTs to test staging
* then deploy to prodddd



=== As Always, Start with a Test

((("environment variables")))
((("staging sites", "adapting functional tests for", id="SSadapt09")))
Let's adapt our functional tests slightly
so that it can be run against a standalone server,
instead of the one that `LiveServerTestCase` creates for us.
We'll do it by checking for an environment variable
called `TEST_SERVER`:


[role="sourcecode"]
.functional_tests/tests.py (ch08l001)
====
[source,python]
----
import os
[...]

class NewVisitorTest(StaticLiveServerTestCase):

    def setUp(self):
        self.browser = webdriver.Firefox()
        test_server = os.environ.get('TEST_SERVER')  #<1>
        if test_server:
            self.live_server_url = 'http://' + test_server  #<2>
----
====


Do you remember I said that `LiveServerTestCase` had certain limitations?
Well, one is that it always assumes you want to use its own test server, which
it makes available at `self.live_server_url`.  I still want to be able to do
that sometimes, but I also want to be able to selectively tell it not to
bother, and to use a real server instead.

<1> The way I decided to do it is using an environment variable called
    `TEST_SERVER`.

<2> Here's the hack: we replace `self.live_server_url` with the address of
    our "real" server.

We test that said hack hasn't broken anything by running the functional
tests [keep-together]#"normally"#:

[subs="specialcharacters,macros"]
----
$ pass:quotes[*python manage.py test functional_tests*]
[...]
Ran 3 tests in 8.544s

OK
----

And now we can try them against our docker server URL,
which once we've done the right docker magic,
will be at _http://locahost:8888_

TIP: I'm deliberately choosing a different port to run Dockerised Django on (8888)
    from the default port that a local `manage.py runserver` would choose (8080),
    to avoid getting in the situation where I _think_ I (or my tests)
    are looking at Docker, when they're actually looking at a local `runserver`
    that I'd left running in some terminal somewhere.


[role="small-code"]
[subs="specialcharacters,macros"]
----
$ pass:quotes[*TEST_SERVER=localhost:8888 python manage.py test functional_tests*]

EEE
======================================================================
ERROR: test_can_start_a_list_for_one_user
(functional_tests.tests.NewVisitorTest)
 ---------------------------------------------------------------------
Traceback (most recent call last):
  File "...goat-book/functional_tests/tests.py", line 41, in
test_can_start_a_list_for_one_user
    self.browser.get(self.live_server_url)
[...]
selenium.common.exceptions.WebDriverException: Message: Reached error page: abo
ut:neterror?e=connectionFailure&u=http%3A//localhost:8888/&c=UTF-8&
f=regular&d=Firefox%20can%27t%20establish%20a%20connection%20to%20the%20server%
20at%20locahost.


======================================================================
ERROR: test_layout_and_styling (functional_tests.tests.NewVisitorTest)
 ---------------------------------------------------------------------
Traceback (most recent call last):
  File "...goat-book/functional_tests/tests.py", line 126, in
test_layout_and_styling
[...]
selenium.common.exceptions.WebDriverException: Message: Reached error page: abo
[...]


======================================================================
ERROR: test_multiple_users_can_start_lists_at_different_urls
(functional_tests.tests.NewVisitorTest)
 ---------------------------------------------------------------------
Traceback (most recent call last):
  File "...goat-book/functional_tests/tests.py", line 80, in
test_multiple_users_can_start_lists_at_different_urls
[...]
selenium.common.exceptions.WebDriverException: Message: Reached error page: abo
[...]

Ran 3 tests in 10.518s

FAILED (errors=3)
----

NOTE: If, on Windows, you see an error saying something like
    "TEST_SERVER is not recognized as a command", it's probably because
    you're not using Git-Bash.  Take another look at the
    <<pre-requisites>> section.

You can see that all the tests are failing, as expected,
since we're not running Docker yet.
Selenium reports that Firefox is seeing an error
and "cannot establish connection to the server".


((("", startref="SSadapt09")))
The FT seems to be testing the right things though, so let's commit:

[subs="specialcharacters,quotes"]
----
$ *git diff* # should show changes to functional_tests.py
$ *git commit -am "Hack FT runner to be able to test docker"*
----


TIP: Don't use `export` to set the 'TEST_SERVER' environment variable;
    otherwise, all your subsequent test runs in that terminal will be against
    staging (and that can be very confusing if you're not expecting it).
    Setting it explicitly inline each time you run the FTs is best.


==== Preparing for deployment: making a src folder


[subs="specialcharacters,quotes"]
----
$ *mkdir src*
$ *git mv * src*
$ *git commit -m "Move all our code into a src folder"*
----


=== Installing Docker


* follow instructions on web
* test with `docker run busybox` or summink.


=== A First Cut of a Dockerfile

Think of a Dockerfile as defining a brand new computer,
that we're going to use to run our django server on.
What do we need to do?  Something like this, right?

1. Install an operating system
2. Make sure it has Python on it
3. Get our source code onto it
4. Run `python manage.py runserver`


.Dockerfile
====
[source,dockerfile]
----
FROM python:slim  <1>

COPY src /src  <2>

WORKDIR /src  <3>

CMD python manage.py runserver  <4>
----
====

<1> The `FROM` line is usually the first thing in a Dockerfile,
    and it says which _base image_ we are starting from.
    Docker images are built from other Docker images!
    It's not quite turtles all the way down, but almost.
    So this is the equivalent of choosing a base operating system,
    but images can actually have lots of software preinstalled too.
    You can browse various base images on DockerHub,
    we're using one that's published by the Python Software Foundation,
    called "slim" because it's as small as possible.
    It's based on a popular version of Linux called Debian,
    and of course it comes with Python already installed on it.

<2> The `COPY` command lets you copy files
    from your own computer into the container image.
    We use it to copy all our source code from the newly-created _src_ folder,
    into a similary named folder at the root of the container image

<3> `WORKDIR` sets the current working directory for all subsequent commands.
     It's a bit like doing `cd /src`

<4> Finally the `CMD`, er, command tells docker wich, um,
    command you want it to run by default,
    when you start a container based on that image.

// deliberately wont work, django not installed


=== Building a Docker Image and Running a Docker Container

* intro to build vs run

==== Docker build

You build a container with `docker build <path-containing-dockerfile>`
and we'll use the `-t <tagname>` argument to "tag" our image
with a memorable name.

It's typical to invoke `docker build` from the folder that contains your Dockerfile,
so the last argument is usally `.`:

[subs="specialcharacters,macros"]
----
$ pass:quotes[*docker build -t superlists .*]

[+] Building 8.4s (8/8) FINISHED                            docker:default
 => [internal] load build definition from Dockerfile                  0.0s
 => => transferring dockerfile: 115B                                  0.0s
 => [internal] load .dockerignore                                     0.1s
 => => transferring context: 2B                                       0.0s
 => [internal] load metadata for docker.io/library/python:slim        0.0s
 => [internal] load build context                                     0.2s
 => => transferring context: 68.54kB                                  0.1s
 => [1/3] FROM docker.io/library/python:slim                          0.0s
 => CACHED [2/3] COPY src /src                                        0.0s
 => CACHED [3/3] WORKDIR /src                                         0.0s
 => exporting to image                                                0.0s
 => => exporting layers                                               0.0s
 => => writing image sha256:7b8e1c9fa68e7bad7994fa41e2aca852ca79f01a  0.0s
 => => naming to docker.io/library/superlists                         0.0s
----

Now we can see our image in the list of docker images on the system:

----
$ pass:quotes[*docker images*]
REPOSITORY    TAG       IMAGE ID       CREATED          SIZE
superlists    latest    7b8e1c9fa68e   13 minutes ago   155MB
----



==== Docker run


Once you've built an image,
you can run one or more containers based on that image, using `docker run`.
What happens when we run ours?
Again, we'll use the `-t` argument to find our image using its tag:


[subs="specialcharacters,macros"]
----
$ pass:quotes[*docker run superlists*]
Traceback (most recent call last):
  File "/src/manage.py", line 11, in main
    from django.core.management import execute_from_command_line
ModuleNotFoundError: No module named 'django'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/src/manage.py", line 22, in <module>
    main()
  File "/src/manage.py", line 13, in main
    raise ImportError(
ImportError: Couldn't import Django. Are you sure it's installed and available
on your PYTHONPATH environment variable? Did you forget to activate a virtual
environment?
----

TODO: note on the fact that you can't ctrl-c the process.
    explain docker -it.


Ah, we forgot that we need to install Django.


=== Virtualenv and requirements.txt

Just like on our own machine,
a virtualenv is useful in a deployed environment to make
sure we have full control over the packages installed for a particular
project.

To reproduce our local virtualenv,
rather than just manually pip installing things
one by one, and having to remember to sync things
between local dev and docker,
we can "save" the list of packages we're using
by creating a 'requirements.txt' filefootnote:[
There are many other dependency management tools these days
so requirements.txt is not the only way to do it,
although it is one of the oldest and best established.
As you continue your Python adventures
I'm sure you'll come across many others.]


[subs="specialcharacters,quotes"]
----
$ *pip freeze*
# shows all ur packages. Find django
$ *pip freeze | grep -i django== >> requirements.txt*
$ *git add requirements.txt*
$ *git commit -m "Add requirements.txt for virtualenv"*
----

You may be wondering why we didn't add our other dependency,
Selenium, to our requirements.
As always, I have to gloss over some nuance and tradeoffs,
but the short answer is that Selenium is only a dependency for the tests,
not the application code;
we're never going to run the tests directly on our production servers.

NOTE: When you have a moment,
    you might want to do some further reading
    on running your tests in Docker,
    and generating "lockfiles".

In any case, back in our Dockerfile, we can create a virtualenv
just like we did on our own machine with `python -m venv`,
and then we can use the special `-r` flag for `pip install`,
to point it at our requirements file:

.Dockerfile
====
[source,dockerfile]
----
FROM python:slim

RUN python -m venv /venv  <1>

COPY requirements.txt requirements.txt  <2>
RUN /venv/bin/pip install -r requirements.txt  <3>

COPY src /src

WORKDIR /src

CMD /venv/bin/python manage.py runserver  <4>
----
====

<1> Here's where we create our virtualenv
<2> We copy our requirements file in, just like the src folder
<3> You can't really "activate" a virtualenv inside a Dockerfile,
    so instead we provide the full path to the virtualenv version of `pip`
    when we want to do the `pip install`.
    Notice the `-r`
<4> Relatedly, we switch from using the system default Python
    to using the full path to the Python that's in our virtualenv,
    when running `manage.py`.

TIP: Forgetting the `-r` and running `pip install requirements.txt`
    is such a common error, that I recommend you do it _right now_
    and get familiar with the error message,
    because (at the time of writing), it's not that helpful.
    And it's a mistake I still make, all the time..


==== database migration

when we run it we spot a warning about migrations

[subs="specialcharacters,quotes"]
----
$ *docker run -it superlists*
You have 19 unapplied migration(s). Your project may not work properly until
you apply the migrations for app(s): auth, contenttypes, lists, sessions.
Run 'python manage.py migrate' to apply them.
----

// TODO; need to introduce mounts at some point, db can't be in the container image.
// or switch to postgres but that's a big hassle.

so we add that to our dockerfile


[role="sourcecode"]
.Dockerfile
====
[source,dockerfile]
----
RUN /venv/bin/python manage.py migrate

CMD /venv/bin/python manage.py runserver
----
====

and try again

////
old content follows.  consider "failing to notice" the migrations warning
and letting this happen naturally instead.

A quick visual inspection confirms--the site is up (<<staging-is-up>>)!

[[staging-is-up]]
.The staging site is up!
image::images/twp2_0903.png["The front page of the site, at least, is up"]

Let's see what our functional tests say:

[role="small-code"]
[subs="specialcharacters,macros"]
----
$ pass:quotes[*TEST_SERVER=superlists-staging.ottg.eu:8000 ./manage.py test functional_tests \
    --failfast*]
[...]
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate
element: [id="id_list_table"]
----


The tests are failing as soon as they try to submit a new item, because we
haven't set up the database. You'll probably have spotted the yellow Django
debug page (<<django-debug-screen>>) telling us as much as the tests went
through, or if you tried it manually.


NOTE: The tests saved us from potential embarrassment there.  The site 'looked'
    fine when we loaded its front page.  If we'd been a little hasty and only
    testing manually, we might have thought we were done, and it would have
    been the first users that discovered that nasty Django DEBUG page.  Okay,
    slight exaggeration for effect, maybe we 'would' have checked, but what
    happens as the site gets bigger and more complex? You can't check
    everything. The tests can.

[[django-debug-screen]]
.But the database isn't
image::images/twp2_0904.png["Django DEBUG page showing database error"]



Creating the Database with migrate
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

((("database migrations")))We
run `migrate` using the `--noinput` argument to suppress the two little "are
you sure" prompts:

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *./.venv/bin/python manage.py migrate --noinput*
Operations to perform:
  Apply all migrations: auth, contenttypes, lists, sessions
Running migrations:
  Applying contenttypes.0001_initial... OK
  [...]
  Applying lists.0004_item_list... OK
  Applying sessions.0001_initial... OK
----

That looks good.  We restart the server:


[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *./.venv/bin/python manage.py runserver 0.0.0.0:8000*
----

And try the FTs again:

[role="small-code"]
[subs="specialcharacters,macros"]
----
$ pass:quotes[*TEST_SERVER=superlists-staging.ottg.eu:8000 ./manage.py test functional_tests*]
[...]

...
 ---------------------------------------------------------------------
Ran 3 tests in 10.718s

OK
----
////



==== ports

doesnt work, show screenshot, and/or ft run.

[subs="specialcharacters,macros"]
----
$ pass:quotes[*TEST_SERVER=localhost:8888 ./manage.py test functional_tests \

selenium.common.exceptions.WebDriverException: Message: Reached error page: about:neterror[...]
----

----
CMD /venv/bin/python manage.py runserver  <4>
----



=== Using the FT to Check That Our Container Works

Let's see what our FTs think about this Docker version of our site.
I'll use the `--failfast` option to exit as soon as a single test fails:


[role="small-code"]
[subs="specialcharacters,macros"]
----
$ pass:quotes[*TEST_SERVER=localhost:8888 ./manage.py test functional_tests \
    --failfast*]
[...]
selenium.common.exceptions.WebDriverException: Message: Reached error page: [...]
----

Nope!  What's going on here?  Time for a little debugging.



=== Debugging a Container Networking Problems

First let's try and take a look ourselves, in our browser:

[[firefox-unable-to-connect-screenshot]]
.Cannot connect on that port
image::images/firefox-unable-to-connect.png["Firefox showing the 'Unable to connect' error"]


Now let's take another look at the output from our `docker run`


----
Starting development server at http://127.0.0.1:8000/
Quit the server with CONTROL-C.
----

Aha, wrong port.  Let's change that:

.Dockerfile
====
[source,dockerfile]
----
CMD /venv/bin/python manage.py runserver 8888
----

Still won't work.

////

OLD CONTENT FOLLOWS

Nope, that didn't work earlier.  Let's try an even lower-level smoke test, the
traditional Unix utility "curl" -- it's a command-line tool for making web
requests.  Try it on your own computer first:

[role='ignore-errors']
[subs="specialcharacters,quotes"]
----
$ *curl localhost:8888*
curl: (7) Failed to connect to localhost:8888: Connection
refused
----

And maybe just to be sure, we could even open up our web browser and type in
'http://localhost:8888', and confirm using a familiar tool
that things aren't working. Nope.
////


=== Running code "inside" the container with docker exec

// TODO use --name arg to docker run??

[subs="specialcharacters,quotes"]
----
$ *docker ps*  # make not of container name
$ *docker exec -it <container-name> bash*
$ *apt-get update*
Get:1 http://deb.debian.org/debian bookworm InRelease [151 kB]
Get:2 http://deb.debian.org/debian bookworm-updates InRelease [52.1 kB]
Get:3 http://deb.debian.org/debian-security bookworm-security InRelease [48.0 kB]
[...]
$ *apt-get install curl*
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
The following additional packages will be installed:
  libbrotli1 libcurl4 libldap-2.5-0 libldap-common libnghttp2-14 libpsl5
librtmp1 libsasl2-2 libsasl2-modules
  libsasl2-modules-db libssh2-1 publicsuffix
[...]
$ *curl -iv http://localhost:8000*
*   Trying 127.0.0.1:8000...
* Connected to localhost (127.0.0.1) port 8000 (#0)
> GET / HTTP/1.1
> Host: localhost:8000
> User-Agent: curl/7.88.1
> Accept: */*
>
< HTTP/1.1 200 OK
HTTP/1.1 200 OK
[...]
<!doctype html>
<html lang="en">

  <head>
    <title>To-Do lists</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="/static/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  </head>

  <body>
[...]
----

OK so we can see django is serving our site _inside_ the container,
why can't we see it _outside_??

Basically we need to do two things:

==== exposing docker ports

docker runs in its own little world,
need to expose ports.  explain A:B syntax.

[subs="specialcharacters,quotes"]
----
$ *podman run -p 8888:8888 -it superlists*
----

==== Essential Googling the Error Message

the `-p` argument to `docker run` is something you just learn,
fairly on in learning docker.
But the next debugging step is a fair bit more obscure.
We'll have to resort to the tried and tested
"Googling the error message" technique instead
(<<googling-the-error>>).


[[googling-the-error]]
.An indispensable publication (source: https://news.ycombinator.com/item?id=11459601[])
image::images/orly-essential-googling-the-error-message.png["Cover of a fake O'Reilly book called Googling the Error Message",400]


Everyone's search results are a little different,
and mine are perhaps shaped by years of working with docker and django,
but I found the answer in my very first result
(see <<google-results-screenshot>>),
which was a https://stackoverflow.com/questions/49476217/docker-cant-access-django-server[stackoverflow post].


[[google-results-screenshot]]
.Google can still deliver results
image::images/google-results-with-stackoverflow.png["Google results with a useful stackoverflow post in first position",400]


So we need to tell django to bind to any IP address,
because container networking doesn't always have 127.0.0.1
as the address of _localhost_:

.Dockerfile
====
[source,dockerfile]
----
CMD /venv/bin/python manage.py runserver 0.0.0.0:8888
----

.On Debugging
*******************************************************************************
Let me let you in on a little secret.  I'm actually bad at debugging.
We all have our psychological strengths and weakness,
and one of my weaknesses is
that when I run into a problem I can't see an obvious solution to,
I want to throw up my hands way too soon
and say "well, this is hopeless, it can't be fixed",
and give up.

Thankfully I have had some good role models over the years
who are much better at it than me (hi Glenn!).
Debugging needs the patience and tenacity of a bloodhound.
If at first you don't succeed,
you need to systematically rule out options,
check your assumptions,
eliminate various aspects of the problem and simplify things down,
find the parts that do and don't work,
until you eventually find the cause.

It always seems hopeless at first!  But eventually you get there.

*******************************************************************************



Let's try our FTs again:


[role="small-code"]
[subs="specialcharacters,macros"]
----
$ pass:quotes[*TEST_SERVER=superlists-staging.ottg.eu:8000 ./manage.py test functional_tests \
    --failfast*]
Found 3 test(s).
Creating test database for alias 'default'...
System check identified no issues (0 silenced).
...
 ---------------------------------------------------------------------
Ran 3 tests in 26.965s

OK
----



AMAZING IT ACTUALLY WORKS

commit commit commit.

Time for a well-earned tea break I think, and perhaps a
https://en.wikipedia.org/wiki/Digestive_biscuit[chocolate biscuit].


Success!  Our Hack Deployment Works
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Phew.  Well, it took a bit of hacking about, but now we can be reassured that
the basic piping works. Notice that the FT was able to guide us incrementally
towards a working site.

But we really can't be using the Django dev server in production, or running on
port 8888 forever. In the next chapter, we'll make our hacky deployment more
production-ready.


.Test-Driving Server Configuration and Deployment
*******************************************************************************

Tests and small steps some of the uncertainty out of deployment::
    For developers, ops and infra work is always "fun",
    by which I mean a process full of uncertainty and surprises.
    My aim during this chapter was to show that a step-by-step approach
    helps to minimse risk, especially when allied to a functional test suite 
    that can help us to catch errors early.

// TODO amend the rest
Some typical pain points--networking, ports, static files, and the database::
    The things that you need to keep an eye out for on any deployment include
    making sure your database configuration, static files, software
    dependencies, and custom settings that differ between development and
    production.  You'll need to think through each of these for your own
    deployments.

Tests allow us to experiment and work incrementally::
    Whenever we make a change to our server configuration, we can rerun the
    test suite, and be confident that everything works as well as it did
    before.  It allows us to experiment with our setup with less fear (as
    we'll see in the next chapter).

*******************************************************************************
